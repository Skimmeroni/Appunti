\begin{sile}

	Un algoritmo di ricerca \strong{informato} possiede informazioni
	in merito a "quanto vicino" sia uno stato rispetto agli obiettivi.
	A differenza degli algoritmi di ricerca non informati, gli algoritmi
	di ricerca informati possono orientare la loro computazione verso
	una determinata "direzione".

	Viene detta \strong{funzione di euristica}, o semplicemente
	\strong{euristica}, una funzione che fornisce informazioni
	piú o meno precise su quanto lo stato generico di un problema
	sia vicino ad uno stato obiettivo del medesimo problema. Nello
	specifico: tale funzione, indicata con \math{h(n)}, restituisce
	una stima numerica del percorso a costo minimo che ha inizio nel
	nodo \math{n} e ha fine nel nodo con stato obiettivo piú vicino.
	Si noti come una euristica indichi semplicemente una ipotetica
	direzione "privilegiata" da seguire, ma non garantisca in alcun
	modo che seguendo tale direzione si raggiunga la soluzione
	con il minimo costo.

	\begin{example}
		Si estenda il problema dell'esempio precedente introducendo
		degli ostacoli lungo il percorso. In questo modo, da ciascuna
		cella della griglia è possibile muoversi solamente in specifiche
		direzioni. Questo significa che il problema di raggiungere la
		cella (4,4) non ha più per soluzione quella presentata, perchè
		potrebbe non essere più valida. Tuttavia, è garantito che
		qualsiasi soluzione non possa essere migliore, in termini
		di costo, di quella ipotetica presentata. Per questo motivo,
		Il numero di celle fra quella attuale e quella obiettivo è una
		possibile euristica per il problema di ricerca.
	\end{example}

	I modi per costruire una euristica sono molteplici. Il piu semplice
	consiste nel costruire una versione "semplificata" del problema in
	esame, detta \strong{problema rilassato}, analogo in tutto al problema
	originale meno che nella funzione di transizione. Questa viene infatti
	ampliata aggiungendo azioni che permettono di raggiungere in meno passi
	lo stato obiettivo da qualsiasi stato. In questo modo, si ottiene un
	limite inferiore al numero di azioni necessarie a raggiungere uno stato
	obiettivo nel problema originario; tale limite inferiore diviene la
	funzione di euristica.

	\begin{example}
		Cio che e stato fatto nel precedente esempio e un esempio di
		costruzione di un problema rilassato, introducendo azioni
		aggiuntive che permettono a Pacman di muoversi ignorando gli
		ostacoli ed individuando un limite inferiore al numero di azioni
		necessarie.
	\end{example}

	Una euristica si dice \strong{ammissibile} se approssima sempre i costi
	per difetto. Ovvero, sia \math{h*(n)} l'effettivo costo minimo necessario
	a raggiungere il piu vicino stato obiettivo per un nodo \math{n}; una
	euristica \math{h(n)} e ammissibile se vale \math{h(n) \leq h*(n)} per
	qualsiasi \math{n}.

	Una euristica \math{h(n)} si dice \strong{consistente} se, per ogni nodo
	\math{n} e per ogni successore \math{n'} di \math{n} generato dall'azione
	\math{a}, vale:

	\begin[mode = display]{math}
		h(n) \leq \mi{COST}(n, a, n') + h(n')
	\end{math}

	Che non é altro che la disuguaglianza triangolare rispetto all'euristica.

	La proprietá di consistenza é piú forte dell'ammissibilitá, perché ogni
	euristica consistente é anche ammissibile, ma non tutte le euristiche
	ammissibili sono consistenti. Inoltre, se l'euristica é consistente,
	quando viene raggiunto un nodo per la prima volta si ha la certezza che
	questo si trovi su uno dei percorsi ottimali, e non verrá mai aggiunto
	alla frontiera piú di una volta.

	Date piú euristiche ammissibili per il medesimo problema, é possibile
	compararle per valutare quale sia la migliore. Se date due euristiche
	\math{h_{1}} e \math{h_{2}} vale \math{h_{1}(n) \geq h_{2}(n)} per ogni
	valore di \math{n}, si dice che \math{h_{1}} \strong{domina} \math{h_{2}}.
	Se l'euristica \math{h_{1}} domina \math{h_{2}}, allora \math{h_{1}} é
	sempre una euristica migliore di \math{h_{2}}, perché il bound restituito
	da \math{h_{1}} sará sempre maggiore di quello restituito da \math{h_{2}},
	e sará quindi piú vicino all'effettivo valore della soluzione ottimale.

	Se vale \math{h_{1}(n) \geq h_{2}(n)} solo per alcuni valori di \math{n},
	una euristica che certamente domina entrambe é \math{h(n) = \mi{max}
	(h_{1}(n), h_{2}(n))}, perché per tutti i possibili \math{n} varrá sempre
	\math{h(n) = h_{1}(n)} e \math{h(n) \geq h_{2}(n)} oppure \math{h(n) =
	h_{2}(n)} e \math{h(n) \geq h_{1}(n)}. Inoltre, il massimo di piú euristiche
	ammissibili é sempre un'euristica ammissibile a sua volta.

	\subsection{Greedy Search}

		L'algoritmo \strong{Greedy Search} adotta la strategia di
		scegliere di espandere sempre il nodo il cui valore di
		euristica è il minore possibile, ovvero il nodo \math{n}
		che minimizza la funzione \math{h(n)}. Il nodo viene scelto
		a prescindere da quale questo sia e da che risultato abbia
		la relativa espansione. Nella migliore delle ipotesi, questo
		permette di raggiungere una soluzione velocemente; nella
		peggiore delle ipotesi, Greedy Search di fatto è assimilabile
		ad una versione "guidata" di Depth-First Search. Greedy Search
		è classificabile come algoritmo greedy in quanto la scelta
		localmente ottima (il nodo che minimizza la funzione di
		euristica) viene assunta come scelta globalmente ottima,
		ovvero assumendo che tale nodo sia effettivamente parte di
		una soluzione ottimale.

		Per quanto l'algoritmo sia completo (fintanto che lo spazio
		degli stati è finito), in genere non è ottimale, perchè nulla
		garantisce che i nodi aventi minimo valore di euristica siano
		tutti parte di una soluzione ottima. Comportandosi
		approssimativamente come DFS, Greedy Search ha un costo in
		termini di spazio pari a \math{O(bD)}. Le performance in
		termini di tempo sono fortemente influenzate dalla scelta
		dell'euristica: sebbene il tempo di esecuzione teorico sia
		\math{O(b^{d})}, una buona euristica permette di abbassare
		considerevolmente tale limite, in certi casi anche fino a
		\math{O(bm)}.

		Esistono problemi dove è noto a priori che l'euristica
		sia "infallibile", ovvero che se un nodo ha un valore
		di euristica minimo allora è certamente parte di una
		soluzione ottimale. In tali casi, è sostanzialmente
		garantito che Greedy Search sia l'algoritmo di ricerca
		con le migliori prestazioni.

	\subsection{A* Search}

		Il piú comune algoritmo di ricerca informato é
		\strong{A* Search} (pronuncia: "A-star search"),
		che combina gli approcci di Uniform Cost search
		e di Greedy Search. La strategia dell'algoritmo
		prevede di espandere il nodo che è sia quello 
		"suggerito" dall'euristica sia quello che richiede
		il minimo costo per raggiungerlo.

		Nello specifico, A* Search prevede di espandere il
		nodo \math{n} che minimizza la funzione \math{f(n)
		= h(n) + g(n)}, dove \math{h(n)} è la funzione di
		euristica e \math{g(n)} è il costo totale associato
		al raggiungere il nodo. Le due funzioni vengono
		anche chiamate rispettivamente \strong{forward cost}
		e \strong{backward cost}. La frontiera viene salvata
		in una coda di priorità ordinata in ordine decrescente
		rispetto a \math{f(n)}, di modo che il nodo estratto
		sia sempre quello che minimizza tale funzione.

		Le prestazioni in termini di tempo impiegato e spazio
		occupato da A* search sono le medesime di UCS. Fintanto
		che lo spazio degli stati e finito, A* search é un
		algoritmo completo. L'ottimalita di A* search dipende
		dalle caratteristiche della funzione di euristica.

		\begin{theorem}
			Se A* search su alberi utilizza una euristica
			ammissibile, A* search e ottimale.
		
			\bigskip
			\strong{Dimostrazione}.	Si consideri un problema di
			ricerca su cui viene applicato A* search avente almeno
			due nodi obiettivo: \math{A} e \math{B}, dove il percorso
			ottimale dalla radice ad \math{A} e la soluzione meno
			costosa. Sia poi \math{h(n)} una funzione di euristica
			ammissibile applicata alla risoluzione del problema. Se
			A* search e ottimale, il nodo \math{A} deve venire espanso
			prima di \math{B}.

			\bigskip
			Si assuma che la frontiera contenga il nodo \math{B} ed
			almeno un altro nodo non obiettivo \math{n}, il quale si
			trova sul percorso ottimale dalla radice ad \math{A}.
			Il nodo \math{n} potrebbe coincidere con \math{A} stesso.
			Se A* search e ottimale, \math{n} deve venire espanso prima
			di \math{B}.

			Per definizione, si ha \math{f(n) = g(n) + h(n)}. Essendo
			l'euristica ammissibile, deve aversi \math{f(n) \leq g(n)
			+ h*(n)}. Tuttavia, la somma fra il backward cost (il costo
			minimo dalla radice ad \math{n}) ed il forward cost (il costo
			minimo da \math{n} ad \math{A}) coincide esattamente con il
			costo minimo dalla radice ad \math{A}, pertanto \math{g(n) +
			h*(n) = g(A)}. Sostituendo nella relazione precedente, si ha
			\math{f(n) \leq g(A)}. Si osservi inoltre come \math{h(A)},
			essendo \math{A} uno stato obiettivo, e nullo, pertanto
			\math{f(A) = g(A) + 0 = g(A)}. E allora possibile scrivere
			\math{f(n) \leq f(A)}.

			Essendo per definizione il percorso dalla radice a \math{B}
			piu costoso del percorso dalla radice ad \math{A}, si ha
			\math{g(A) < g(B)}. Inoltre, essendo \math{B} uno nodo
			obiettivo, deve aversi \math{f(B) = g(B)}; sostituendo nella
			precedente, si ha \math{g(A) < f(B)}. Essendo pero \math{f(A)
			= g(A)}, si ha \math{f(A) < f(B)}. Avendosi pero trovato che
			\math{f(n) \leq f(A)}, e possibile concludere che \math{f(n)
			< f(B)}.

			\bigskip
			Dato che A* search espande il nodo della frontiera che minimizza
			\math{f(n)}, e certo che venga espanso prima \math{n} di \math{B}.
			Essendo pero \math{n} un qualsiasi nodo lungo il percorso ottimale
			dalla radice ad \math{A}, significa che tutti i nodi che si trovano
			lungo il percorso ottimale dalla radice ad \math{A} verranno espansi
			prima di \math{B}. Tuttavia, \math{n} potrebbe coincidere con \math{A},
			pertanto e possibile assumere che \math{A} venga espanso prima di
			\math{B}. Questo prova che A* search e un algoritmo ottimale.
		\end{theorem}

		\begin{theorem}
			Se A* search su grafi utilizza una euristica consistente,
			A* search e ottimale.

			%\bigskip
			%\strong{Dimostrazione}. Si consideri un problema di ricerca
			%su cui viene applicato A* search su grafi con una euristica
			%consistente. Presi due nodi \math{n} e \math{n'}, deve 
			%valere
			%
			%\begin[mode = display]{math}
			%	h(n) \leq \mi{COST}(n, a, n') + h(n')
			%	\thickspace\Rightarrow\thickspace
			%	h(n) + g(n) \leq \mi{COST}(n, a, n') + h(n') + g(n)
			%	\thickspace\Rightarrow\thickspace	
			%	f(n) \leq \mi{COST}(n, a, n') + h(n') + g(n)
			%\end{math}
		\end{theorem}

\end{sile}
