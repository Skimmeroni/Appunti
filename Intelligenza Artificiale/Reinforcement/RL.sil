\begin{sile}

	La forma di model-free reinforcement learning piú comune
	é chiamata \strong{Q-learning}, dove l'agente apprende
	una Q-function \math{Q(s, a)}, che indica la somma delle
	ricompense che si avranno a partire dallo stato \math{s}
	se viene intrapresa l'azione \math{a}. Data una Q-function,
	l'agente puó scegliere che azione compiere mentre si trova
	in \math{s} sulla base di quale di queste restituisce il
	Q-value maggiore:

	\begin[mode = display]{math}
		Q(s, a) = r + \phi \mi{max}_{a'} (Q'(s', a'))
	\end{math}

	Dove \math{r} é la ricompensa immediata, \math{\phi} é il
	fattore di sconto e \math{Q'(s', a')} é la ricompensa che
	si otterrebbe raggiungendo lo stato \math{a'}, dove tale
	stato é lo stato che rende il massimo valore possibile.

\end{sile}
