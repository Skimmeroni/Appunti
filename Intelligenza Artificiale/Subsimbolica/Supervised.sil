\begin{sile}

	L'obiettivo del supervised learning é il seguente: dato
	un \strong{training set} di \math{N} esempi, costituiti
	da coppie input-output \math{(x_{1}, y_{1}), (x_{2}, y_{2}),
	\unicodeellipsis, (x_{n}, y_{n})} generati da una funzione
	ignota \math{y = f(x)}, si trovi la funzione \math{h} che
	meglio approssima \math{f}. Si noti come \math{x_{i}} possa
	essere indifferentemente uno scalare oppure un vettore a
	\math{k} componenti.

	La funzione \math{h} viene chiamata \strong{ipotesi}, ed é
	estratta da uno \strong{spazio di ipotesi} \math{H} di possibili
	funzioni. Con un diverso vocabolario é possibile chiamare \math{h}
	il \strong{modello} dei dati, estratto da una \strong{classe di 
	modelli} \math{H}, oppure come una \strong{funzione} estratta da
	una \strong{classe di funzioni}. I valori dell'output \math{y_{i}}
	vengono chiamati \strong{veritá di base}: rappresentano i valori
	"reali" che il modello deve cercare di prevedere.

	Per scegliere lo spazio di ipotesi, é possibile rifarsi, se esiste
	a della conoscenza pregressa che ha generato i dati. Se questa
	non esiste, é possibile operare una \strong{analisi dei dati
	esplorativa}, visualizzando i dati (attraverso istogrammi,
	diagrammi a dispersione, ecc\ddd) e operando test statistici
	per avere una idea di quale spazio di ipotesi potrebbe essere
	appropriato.

	Per scegliere l'ipotesi a partire dallo spazio di ipotesi, la
	situazione ideale sarebbe quella di avere una \strong{ipotesi
	consistente}, dove \math{h} é una stima "perfetta" di \math{f}.
	Ovvero, per ciascuna coppia input-output \math{(x_{i}, y_{i})},
	si ha \math{h(x_{i}) = f(x_{i}) = y_{i}}. Naturalmente, questa
	situazione é molto improbabile che possa verificarsi: lo scenario
	migliore é quello in cui, per ciascuna coppia input-output
	\math{(x_{i}, y_{i})}, \math{h(x_{i})} restituisce un valore
	"sufficientemente vicino" a \math{y_{i}}.

	\begin{example}
		Un esempio di supervised learning si ha nei filtri antispam
		dei client di posta elettronica. L'idea é quella di fornire
		al filtro un grande quantitativo di email contrassegnate come
		spam ed un grande quantitativo di email contrassegnate come
		non spam, di modo che questo possa estrarre dei pattern comuni
		nelle email spam e non spam. A questo punto, se viene fornita
		al filtro una mail qualsiasi, questo é (dovrebbe essere) in
		grado di determinare autonomamente se la mail é o non é spam. 
	\end{example}

	La qualitá di una ipotesi, una volta che tale ipotesi é stata
	determinata, viene analizzata fornendogli in input dei dati che
	non conosce. Una ipotesi \math{h} \strong{generalizza} bene se,
	fornitole un nuovo insieme di coppie input-output \math{(u_{i},
	w_{i})} chiamato \strong{test set}, il valore \math{h(u_{i})} é
	una buona approssimazione di \math{w_{i}} per ogni coppia. 
	Idealmente, si ha:

	\begin[mode = display]{math}
		\mi{Precisione} = \frac{\mi{Test} \thickspace \mi{che}
		\thickspace \mi{approssimano} \thickspace \mi{bene}
		\thickspace \mi{le} \thickspace \mi{osservazioni}}{
		\mi{Numero} \thickspace\mi{totale} \thickspace \mi{di}
		\thickspace \mi{test}}
	\end{math}

	Idealmente, occorre assumere che la distribuzione dei dati
	utilizzati come modello e quella dei dati usati come test 
	siano simili, altrimenti il modello costruito mediante 
	allenamento non sará in grado di predire correttamente i
	dati futuri.

	Un primo modo per analizzare lo spazio di ipotesi é studiare
	il bias che questi impongono. Con \strong{bias} si intende la
	tendenza di una ipotesi predittiva a deviare dal valore atteso
	quando viene valutata sulla media di diversi training set. Se
	l'ipotesi non é in grado di individuare alcun pattern nei dati
	che le vengono forniti, si parla di \strong{sottoadattamento}.
	Questo si verifica, in genere, quando il modello si basa su 
	troppi pochi parametri.

	Un secondo modo per analizzare lo spazio di ipotesi é
	studiarne la \strong{varianza}, ovvero il grado di
	"flessibilitá" dell'ipotesi dovuto alle fluttuazioni
	presenti nel training set. Se l'ipotesi si é troppo
	precisa nel modellare il dataset su cui é stata allenata,
	tanto da non poter essere adattata a dataset leggermente
	diversi, si parla di \strong{sovradattamento}. Questo si
	verifica, in genere, quando il modello si basa su troppi
	parametri.

	L'ipotesi migliore é quella che trova il giusto bilanciamento
	fra bias e varianza, ovvero che é sufficientemente complessa
	da individuare un pattern nel training set ma allo stesso tempo
	sufficientemente espressiva da poter interpretare correttamente
	training set diversi.

	Nel caso in cui non sia possibile determinare con certezza quale
	sia l'ipotesi migliore, é possibile assegnare a ciascuna ipotesi
	un grado di probabilitá. Il supervised learning puó essere fatto
	scegliendo l'ipotesi \math{h*} che, a partire da un training set,
	é piú probabile che sia quella in grado di interpretarlo:

	\begin[mode = display]{math}
		h* = \mi{argmax}_{h \in H} P(h | data) =
		\mi{argmax}_{h \in H} P(data | h) P(h)
	\end{math}

\end{sile}
