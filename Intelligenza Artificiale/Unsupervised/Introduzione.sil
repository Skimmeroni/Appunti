\begin{sile}
	
	Nel \strong{unsupervised learning} l'agente cerca di
	individuare dei pattern solo a partire dall'input ma
	non dall'output. A differenza del supervised learning,
	nell'unsupervised learning non sono note a priori le
	classi in cui gli elementi del dataset vanno catalogati.
	L'idea é che i dati debbano prima venire esplorati per
	individuare se esistono fra loro dei pattern comuni, e
	poi classificare i dati sulla base di questi.

	Piu formalmente, sia \math{D} un insieme di \math{n}
	elementi. Ciascun elemento possiede \math{m} attributi
	\math{A_{1}, A_{2}, \unicodeellipsis, A_{m}}. Ciascuno
	di questi elementi puo essere rappresentato da una
	\math{m}-upla, ovvero come \math{\bi{x}_{1}, \bi{x}_{2},
	\unicodeellipsis, \bi{x}_{n}}. Il valore del \math{j}-esimo
	attributo dell'\math{i}-esimo elemento viene indicato con
	\math{x_{i, j}}.

	Si supponga di poter associare a ciascun \math{i}-esimo
	elemento di \math{D} un valore \math{y_{i}}: tale valore
	dipende da una certa funzione definibile a partire dai
	valori di \math{\bi{x}_{i}}. \math{y_{i}} rappresenta
	la classe a cui l'\math{i}-esimo elemento di \math{D}
	appartiene; si noti come i valori di \math{y_{i}}, a
	differenza del supervised learning, non sono noti.

	L'unsupervised learning apprende solo dall'input in
	questo senso: l'input \math{(\bi{x}_{i})} permette di
	dedurre l'output \math{(y_{i})}, ma i dati di \math{D}
	non contengono gia l'output. Esempi di unsupervised
	learning sono i seguenti:

	\begin{itemize}
		\begin{item}
			\strong{clustering}: individuare delle proprietá
			comuni nell'input e raggruppare l'input in insiemi
			detti cluster sulla base di tali proprietá, senza
			che i cluster siano noti a priori;
		\end{item}
		\begin{item}
			\strong{dimensionality reduction}: trasformare
			dati da uno spazio dimensionale ampio ad uno
			spazio dimensionale piú ristretto, senza che
			questo comporti una perdita (troppo) significativa
			di informazione;
		\begin{item}
			\strong{anomaly detection}: riuscire ad identificare,
			dato un insieme di dati, quei (pochi) elementi che
			deviano in maniera significativa dalla maggioranza e
			la cui presenza non é giustificabile;
		\end{item}
	\end{itemize}

	\begin{example}
		Un esempio di unsupervised learning, in particolare di 
		anomaly detection, é il modo in cui le banche determinano
		se un pagamento é (potenzialmente) avvenuto senza la
		consapevolezza del titolare del conto bancario. L'idea é
		quella di individuare dei pattern negli acquisti fatti 
		usando una determinata carta (cosa viene comprato, a che
		orario, quanti soldi vengono spesi, ecc\ddd) e notificare
		il responsabile se viene effettuato un pagamento che devia
		sensibilmente dalla routine.
	\end{example}

	La forma di unsupervised learning piu rilevante e indubbiamente
	il clustering, tanto che i termini "unsupervised learning"
	e "clustering" sono talvolta usati (non correttamente) come
	sinonimi. 

	Sebbene le tecniche di clustering siano molto diverse, tutte
	fanno uso di una funzione (non necessariamente una metrica)
	di distanza, utilizzata per definire quanto due elementi del
	dataset siano \em{simili}: minore é la distanza, maggiore é
	la somiglianza. Fra le diverse tecniche di clustering e
	possibile citare:

	\begin{itemize}
		\begin{item}
			\strong{Clustering basato su partizioni}, che a partire
			da un dataset uniforme lo partiziona in insiemi sempre
			piu piccoli. In questo tipo di clustering il dataset
			viene preso in esame per intero, a prescindere da quanto
			questo sia rumoroso. Questo semplifica il procedimento,
			perché non e necessario alcun preprocessing, ma allo
			tesso tempo rende i cluster molto suscettibili al rumore
			del dataset, in particolare, agli \strong{outlier}, i
			dati isolati molto distanti dal resto;
		\end{item}
		\begin{item}
			\strong{Clustering basato su densita}, che aggrega in
			cluster elementi che hanno una alta similitudine;
		\end{item}
		\begin{item}
			\strong{Clustering basato su gerarchie}.
		\end{item}
	\end{itemize}

	\bigskip

	Sia il clustering sia la classificazione sono tecniche di
	machine learning in grado di determinare, fornito un certo
	input, a quale classe questo appartiene; eppure, le due
	presentano notevoli differenze. Innanzitutto, come gia detto,
	nel clustering le classi non sono note, dovendo invece venire
	dedotte a partire dal dataset stesso, mentre nella classificazione
	e gia noto quali siano le classi. Questo introduce un'ulteriore
	difficolta, perche ci si aspetta che le classi indotte da un
	algoritmo di clustering abbiano una semantica, mentre se le
	classi sono gia fornite questa e (dovrebbe essere) deducibile
	dalle stesse.

	Il clustering é molto piú "esplorativo" della classificazione,
	tanto che puó essere usato prima di operare un algoritmo di
	classificazione di modo da fornirgli una base d'appoggio.
	Ovvero, prima si approccia il problema come un problema di
	clustering, si analizzano le classi che questo induce,
	eventualmente se ne cambiano e/o se ne eliminano alcune e
	poi sulla base di questa etichettatura si opera un algoritmo
	di classificazione.

\end{sile}
