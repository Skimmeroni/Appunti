\begin{sile}
	
	Nel \strong{unsupervised learning} l'agente cerca di
	individuare dei pattern solo a partire dall'input ma
	non dall'output. A differenza del supervised learning,
	nell'unsupervised learning non sono note a priori le
	classi in cui gli elementi del dataset vanno catalogati.
	L'idea é che i dati debbano prima venire esplorati per
	individuare se esistono fra loro dei pattern comuni, e
	poi classificare i dati sulla base di questi.

	Piu formalmente, sia \math{D} un insieme di \math{n}
	elementi. Ciascun elemento possiede \math{m} attributi
	\math{A_{1}, A_{2}, \unicodeellipsis, A_{m}}. Ciascuno
	di questi elementi puo essere rappresentato da una
	\math{m}-upla, ovvero come \math{\bi{x}_{1}, \bi{x}_{2},
	\unicodeellipsis, \bi{x}_{n}}. Il valore del \math{j}-esimo
	attributo dell'\math{i}-esimo elemento viene indicato con
	\math{x_{i, j}}.

	Si supponga di poter associare a ciascun \math{i}-esimo
	elemento di \math{D} un valore \math{y_{i}}: tale valore
	dipende da una certa funzione definibile a partire dai
	valori di \math{\bi{x}_{i}}. \math{y_{i}} rappresenta
	la classe a cui l'\math{i}-esimo elemento di \math{D}
	appartiene; si noti come i valori di \math{y_{i}}, a
	differenza del supervised learning, non sono noti.

	L'unsupervised learning apprende solo dall'input in
	questo senso: l'input \math{(\bi{x}_{i})} permette di
	dedurre l'output \math{(y_{i})}, ma i dati di \math{D}
	non contengono gia l'output. Esempi di unsupervised
	learning sono i seguenti:

	\begin{itemize}
		\begin{item}
			\strong{clustering}: individuare delle proprietá
			comuni nell'input e raggruppare l'input in insiemi
			detti cluster sulla base di tali proprietá, senza
			che i cluster siano noti a priori;
		\end{item}
		\begin{item}
			\strong{dimensionality reduction}: trasformare
			dati da uno spazio dimensionale ampio ad uno
			spazio dimensionale piú ristretto, senza che
			questo comporti una perdita (troppo) significativa
			di informazione;
		\begin{item}
			\strong{anomaly detection}: riuscire ad identificare,
			dato un insieme di dati, quei (pochi) elementi che
			deviano in maniera significativa dalla maggioranza e
			la cui presenza non é giustificabile;
		\end{item}
	\end{itemize}

	\begin{example}
		Un esempio di unsupervised learning, in particolare di 
		anomaly detection, é il modo in cui le banche determinano
		se un pagamento é (potenzialmente) avvenuto senza la
		consapevolezza del titolare del conto bancario. L'idea é
		quella di individuare dei pattern negli acquisti fatti 
		usando una determinata carta (cosa viene comprato, a che
		orario, quanti soldi vengono spesi, ecc\ddd) e notificare
		il responsabile se viene effettuato un pagamento che devia
		sensibilmente dalla routine.
	\end{example}

	La forma di unsupervised learning piu rilevante e indubbiamente
	il clustering, tanto che i termini "unsupervised learning"
	e "clustering" sono talvolta usati (non correttamente) come
	sinonimi. 

	Sebbene le tecniche di clustering siano molto diverse, tutte
	fanno uso di una funzione (non necessariamente una metrica)
	di distanza, utilizzata per definire quanto due elementi del
	dataset siano \em{simili}: minore é la distanza, maggiore é
	la somiglianza. Fra le diverse tecniche di clustering e
	possibile citare il \strong{clustering basato su partizioni},
	il \strong{clustering basato su densita} ed il \strong{clustering
	basato su gerarchie}.

	Sia il clustering sia la classificazione sono tecniche di
	machine learning in grado di determinare, fornito un certo
	input, a quale classe questo appartiene. La differenza
	fondamentale fra le due sta nel fatto che nel clustering
	le classi non sono note, dovendo invece venire dedotte a
	partire dal dataset stesso, mentre nella classificazione
	e gia noto quali siano le classi.

	Questo comporta delle difficolta, innanzitutto perche ci si
	aspetta che le classi indotte da un algoritmo di clustering
	abbiano una semantica, mentre se le classi sono gia fornite
	questa e (dovrebbe essere) deducibile dalle stesse. Inoltre,
	nella classificazione e possibile comparare i risultati forniti
	dall'algoritmo con i valori del dataset di partenza e valutare
	quanto e buona la predizione. Nel clustering, sebbene sia
	possibile definire delle metriche per valutare i singoli cluster,
	diventa molto difficile determinare la qualita del clustering
	come modello in se, perche non c'e alcun dato di riferimento
	con cui effettuare una comparazione.

	In alcuni contesti, dei dati da utilizzare come comparazione
	per un problema di clustering esiste, ma spesso si tratta di
	informazioni che si trovano al di fuori del dataset. In questo
	caso, é possibile valutare la qualitá del clustering come fosse
	un problema di classificazione. L'idea é quella di trattare
	ciascun cluster come fosse una classe in un problema di
	classificazione, costruire sulla base di queste una matrice
	di confusione ed a sua volta calcolare a partire da questa le
	statistiche di sorta (precision, F-score, ecc\ddd).

	Il clustering é molto piú "esplorativo" della classificazione,
	tanto che puó essere usato prima di operare un algoritmo di
	classificazione di modo da fornirgli una base d'appoggio.
	Ovvero, prima si approccia il problema come un problema di
	clustering, si analizzano le classi che questo induce,
	eventualmente se ne cambiano e/o se ne eliminano alcune e
	poi sulla base di questa etichettatura si opera un algoritmo
	di classificazione. Per questo motivo, un possibile modo per
	valutare la qualitá del clustering é farlo in maniera indiretta
	sulla base della qualitá del risultato finale: se questa é buona,
	allora il clustering che é stato fatto a monte del procedimento
	deve essere stato buono a sua volta.

	In genere, l'unico vero modo per valutare la qualita del
	clustering e l'intervento umano, ad esempio mediante plotting,
	ed osservando il risultato.

\end{sile}
