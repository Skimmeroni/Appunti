\begin{sile}

	Il \strong{supervised learning} e una tecnica di apprendimento
	in cui l'agente apprende sia sulla base dell'input che sulla
	base dell'output. Il nome "supervised" viene dal fatto che
	tale tecnica necessita di dei dati che presentano gia la
	caratteristica che l'agente deve individuare, in modo da
	apprendere quali sono i pattern che portano un dato a possedere
	tale caratteristica. Il supervised learning prevede sia una fase
	di \strong{addestramento}, in cui i pattern vengono individuati,
	ed una fase di \strong{testing}, in cui si valuta se l'algoritmo
	e in grado di prevedere il valore della caratteristica su dati
	ignoti. Naturalmente, e necessario assumere che i dati noti ed
	i dati ignoti abbiano la stessa distribuzione statistica.

	Piu formalmente, sia \math{D} un insieme di \math{n} elementi.
	Ciascun elemento possiede \math{m} attributi \math{A_{1}, A_{2},
	\unicodeellipsis, A_{m}} ed e membro di una classe. Ciascuno di
	questi elementi puo essere rappresentato da una \math{m + 1}-upla,
	ovvero come \math{(\bi{x}_{1}, y_{1}), (\bi{x}_{2}, y_{2}),
	\unicodeellipsis, (\bi{x}_{n}, y_{n})}. \math{\bi{x}_{i}}
	rappresenta i valori degli attributi dell'\math{i}-esimo
	elemento, mentre \math{y_{i}} rappresenta la classe a cui
	l'elemento appartiene. Il valore del \math{j}-esimo attributo
	dell'\math{i}-esimo elemento viene indicato con \math{x_{i, j}}.

	Si assuma l'esistenza di un legame fra i valori di
	\math{\bi{x}_{i}} e quelli di \math{y_{i}}. Deve
	allora esistere una funzione (ignota) \math{f} tale
	che \math{f(\bi{x}_{i}) = y_{i}}, ovvero in grado di
	determinare qual'e il valore di \math{y_{i}} anche se
	questo non e noto, solamente sulla base di \math{\bi{x}_{i}}.

	Il supervised learning costruisce una funzione \math{h},
	chiamata \strong{ipotesi}, che cerca di stimare \math{f}
	osservando i pattern che sussistono fra i valori di
	\math{\bi{x}_{i}} e quelli di \math{y_{i}}. In questo
	modo, se viene fornito in input ad \math{h} una \math{m}-upla
	qualsiasi, questa funzione e in grado di determinare il valore
	di \math{y_{i}} anche se questo e ignoto. Il supervised learning
	apprende sia dall'input che dall'output in questo senso: l'input
	\math{(\bi{x}_{i})} e l'output \math{(y_{i})} sono riferiti alla
	funzione \math{h}, ed entrambi sono necessari alla sua costruzione.

	Il problema risolto dal supervised learning prende una propria
	denominazione in base a qual'e il tipo di dato di \math{y_{i}}.
	Se \math{y_{i}} e un valore numerico, il problema e detto
	\strong{problema di regressione}, in analogia con il concetto
	di regressione matematica. Se \math{y_{i}} e un valore booleano,
	il problema e detto \strong{problema di classificazione},
	perche e possibile interpretare \math{y_{i}} come una variabile
	che indica se l'\math{i}-esimo elemento di \math{D} appartiene
	(\tt{True}) o non appartiene (\tt{False}) ad una certa classe.
	Per convenzione, gli elementi che hanno \tt{True} come valore
	di tale attributo sono detti \strong{elementi positivi}, mentre
	mentre quelli che hanno \tt{False} vengono detti \strong{elementi
	negativi}.

	Il tipo di dato degli attributi determina solamente se questi
	possano essere usati come input di un determinato algoritmo
	oppure no. Infatti, alcuni metodi di apprendimento operano
	esclusivamente su attributi di tipi specifici, mentre altri
	possono operare su attributi eterogenei. E comunque possibile,
	in genere, convertire un attributo di un tipo in uno o piu
	attributi equivalenti mediante una \strong{codifica}.

	Una codifica molto semplice prende il nome di \strong{one hot
	encoding}, applicabile quando il dominio dell'attributo generico
	e discreto e non troppo grande. Questa prevede di sostituire
	l'attributo con tante variabili binarie quanti sono i valori
	che l'attributo puo assumere: se un elemento del dataset aveva
	come \math{i} come valore dell'attributo, allora la \math{i}-esima
	di queste variabili binarie avra valore 1 e tutte le rimanenti
	valore 0.

	\begin{example}
		Un esempio di supervised learning si ha nei filtri antispam
		dei client di posta elettronica. L'idea é quella di fornire
		al filtro un grande quantitativo di email contrassegnate come
		spam ed un grande quantitativo di email contrassegnate come
		non spam, di modo che questo possa estrarre dei pattern comuni
		nelle email spam e non spam. A questo punto, se viene fornita
		al filtro una mail qualsiasi, questo é (dovrebbe essere) in
		grado di determinare autonomamente se la mail é o non é spam. 
	\end{example}

	Vi sono due situazioni patologiche molto comuni che possono
	presentarsi nella costruzione di un modello supervisionato,
	\strong{underfitting} e \strong{overfitting}. La prima si 
	verifica quando il modello costruito predice male i dati
	passati, mentre la seconda si verifica quando il modello
	predice "cosi bene" i dati su cui e allenato da non tollerare
	alcun grado di impurita, tanto da fallire per molti dataset
	solo leggermente differenti Naturalmente, la prima situazione
	e peggiore della seconda, perche se l'overfitting produce
	un modello scadente ma comunque funzionante, l'underfitting
	produce un modello del tutto inutilizzabile.

	Esistono sia algoritmi che costruiscono un modello, e che 
	quindi distinguono fra fase di training e fase di test, 
	chiamati \strong{model-based learning}, sia algoritmi che
	non lo costruiscono, dove tutto e insieme, chiamati
	\strong{individual-based learning}.

	La tecnica piú semplice per allenare un dataset prende il nome
	di \strong{holdout set}. Questa prevede di separare il dataset
	in due sotto-dataset: uno, chiamato \strong{training set}, verrá
	usato per allenare il modello, mentre l'altro, chiamato
	\strong{test set}, verra usato per testarlo. Questa tecnica e
	applicabile quando la dimensione del dataset a disposizione é
	sufficientemente grande da avere due sotto-dataset a loro volta
	grandi. Naturalmente, gli elementi del training set non devono
	figurare nella fase di test, cosi come gli elementi del test
	set non devono figurare nella fase di apprendimento, perche in
	entrambi i casi il modello avrebbe un evidente bias. Separare
	nettamente i due sotto-dataset permette di avere un modello
	funzionante ma che al contempo tollera un minimo margine di
	errore.

	Una tecnica alternativa, chiamata \strong{n-fold
	cross-validation}, é preferibile quando la grandezza
	del dataset a disposizione é limitata. Questa prevede
	di partizionare il dataset a disposizione in \math{m}
	sotto-dataset di uguale grandezza. Per \math{m} volte,
	viene scelto uno degli \math{m} sotto-dataset come test
	set ed i restanti \math{m - 1} sotto-dataset vengono 
	combinati in un training set. A ciascuna iterazione
	della procedura e possibile associare una accuratezza;
	l'accuratezza complessiva viene calcolata come media di
	tutte le \math{m} accuratezze cosí ottenute. In genere,
	sono comuni partizionamenti in 5 (5-fold cross-validation)
	o in 10 (10-fold cross validation) sotto-dataset.

	Nel caso in cui la dimensione del dataset a disposizione
	sia estremamente limitata, é possibile adottare un approccio
	radicale chiamato \strong{leave-one-out cross-validation}, o
	\strong{LOOCV}. L'approccio é di fatto un n-fold cross-validation
	dove la dimensione del test set é unitaria, ovvero se il dataset
	é composto da \math{n} elementi, il sotto-dataset utilizzato per
	la costruzione del modello ha dimensione \math{n - 1} mentre
	quello utilizzato per il testing ha dimensione 1. Come per il
	caso precedente, si ripete l'operazione \math{n} volte e si
	ricava l'accuratezza complessiva a partire dalla media delle
	\math{n} accuratezze parziali.

	Talvolta, trasversalmente a questi approcci, viene introdotto
	un terzo sotto-dataset, chiamato \strong{validation set}.
	Questo viene utilizzato per valutare le prestazioni degli
	\strong{iperparametri}, ovvero i parametri che determinano
	la scelta stessa del tipo di modello. Il modello i cui
	iperparametri sono i piu performanti viene poi allenato con
	il training set e testato con il test set come di consueto.

\end{sile}
