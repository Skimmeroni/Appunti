\begin{sile}

	Il percettrone prima presentato separa gli elementi del dataset
	su cui viene addestrato in maniera netta. Tuttavia, ci si aspetta
	che un dataset sia almeno in minima parte rumoroso, pertanto
	una classificazione così perfetta è del tutto irrealistica. Un
	approccio più ragionevole prevede di separare il dataset sempre
	in due regioni, ma in termini probabilistici: assegnare a ciascun
	elemento del dataset un grado di fiducia sul trovarsi in un'area
	piuttosto che nell'altra. Un percettrone che adotta tale approccio
	prende il nome di \strong{percettrone probabilistico}.

	Il percettrone probabilistico suddivide il dataset sulla base
	della probabilità che un elemento si trovi nell'area in cui è
	stato collocato: più un elemento si trova vicino alla iper-retta
	costruita dal percettrone, maggiore è l'incertezza sulla sua
	classificazione; più è lontano dall'iper-retta e più è ragionevole
	credere che la classificazione di quell'elemento sia corretta.

	Indicando con \math{x} un qualsiasi elemento del dataset, sia 
	\math{P(y | x)} la probabilità di scegliere la classe \math{y}
	prendendo l'elemento \math{x}. Una funzione spesso utilizzata
	per esprimere tale probabilità prende il nome di \strong{softmax}:

	\begin[mode = display]{math}
		P(y | x) = \frac{e^{wy \cdot x}}{e^{wy \cdot x} e^{w\ne y \cdot x}}
	\end{math}

	Dove \math{w} è il vettore dei pesi. Il nome softmax viene dal
	fatto che, con \math{w \rightarrow +\infty}, la funzione diventa
	indistinguibile dalla funzione di max.

	Si presenta però il problema di come addestrare un percettrone di
	questo tipo. Se con il percettrone "classico" veniva sempre assunto
	che la classificazione fosse corretta, ovvero che la classe del
	dato fornito fosse effettivamente la classe a cui appartiene, con
	il percettrone probabilistico questo non è più possibile.

	L'approccio usato prende il nome di \strong{maximum likelihood
	estimation}: dato un modello probabilistico con parametri
	\math{\theta}, la likelihood è la probabilità di osservare un
	certo insieme di dati \math{X} sulla base di \math{\theta}:

	\begin[mode = display]{math}
		\theta_{ML} = \mi{argmax}_{\theta} P(\bi{X} | \theta)
	\end{math}

	In genere si assume che i dati siano statisticamente indipendenti,
	pertanto è possibile semplificare come prodotto delle singole
	osservazioni:

	\begin[mode = display]{math}
		\theta_{ML} = \mi{argmax}_{\theta} P(\bi{X} | \theta) =
		\mi{argmax}_{\theta} \Pi_{i} P_{\theta}(X_{i})
	\end{math}

	Nel percettrone, i dati hanno sia degli attributi che una classe
	a cui appartengono. Per questo motivo, si preferisce studiare la
	\strong{maximum conditional likelihood estimation}:

	\begin[mode = display]{math}
		\theta* = \mi{argmax}_{\theta} P(\bi{Y} | \bi{X}, \theta) =
		\mi{argmax}_{\theta} \Pi_{i} P_{\theta}(y_{i} | x_{i})
	\end{math}

	Ovvero, cercare di massimizzare la probabilità di assegnare ad
	un insieme di attributi la classe corretta. Decidendo di utilizzare
	softmax come funzione di probabilità, si ottiene:

	\begin[mode = display]{math}
		l(w) = \Pi_{i} \frac{e^{w_{yi} x_{i}}}{\sum_{y} e^{w_{yi} x_{i}}}
	\end{math}

	Dove i parametri \math{\theta} sono, in questo caso, i pesi. In
	genere si preferisce studiare la \strong{log likelihood} anzichè
	la likelihood, ovvero:

	\begin[mode = display]{math}
		ll(w) = \sum_{i} \mi{log} P_{w} (y_{i} | x_{i})
		= \sum_{i} w_{yi} x_{i} - \mi{log} \sum_{y} e^{w_{y} x_{i}}
	\end{math}

	Massimizzare questa funzione significa trovare i vettori dei pesi
	\math{w} che meglio rappresentano il tradeoff nell'assegnazione
	delle probabilità fra gli elementi del dataset.

	Molto studio è stato compiuto per cercare la funzione di
	attivazione migliore. Fra i possibili candidati figurano:

	\begin{itemize}
		\begin{item}
			La sigmoide (già introdotta):
			\math{\sigma(x) = 1 / (1 + e^{-x})}

			Vantaggi: ha un codominio semplice, \math{[0, 1]}.
			Storicamente popolare perchè bene approssima il rateo
			di emissione degli impulsi elettrici dei neuroni.

			Svantaggi: i neuroni saturi "uccidono" il gradiente,
			l'output della funzione non è centrato in 0, la funzione
			esponenziale è esosa da calcolare.
		\end{item}
		\begin{item}
			La tangente iperbolica: \math{\mi{tanh}(x)}

			Vantaggi: ha un codominio semplice, \math{[-1, 1]}.
			L'output della funzione è centrato in 0

			Svantaggi: la funzione esponenziale è esosa da calcolare.
		\end{item}
		\begin{item}
			\strong{Rectified Linear Unit}, o \strong{ReLU}:
			\math{\mi{max}(0, x)}

			Vantaggi: non satura nella regione positiva, leggera da
			calcolare, converge più rapidamente delle precedenti.

			Svantaggi: l'output della funzione non è centrato in 0,
			il gradiente non è ben definito quando \math{x < 0}.
		\end{item}
		\begin{item}
			\strong{Leaky ReLU}: \math{\mi{max}(0.01x, x)}

			Vantaggi: non satura nella regione positiva, leggera da
			calcolare, converge più rapidamente delle precedenti, non
			collassa sui valori negativi.

			Svantaggi: l'output della funzione non è centrato in 0
		\end{item}
		\begin{item}
			\strong{Exponential Linear Units}, o \strong{ELU}:
			\begin{math}
				\table[columnalign = left left]{
					x & \mi{se} \thickspace x > 0 \\
					\alpha (e^{x} - 1) & \mi{se} \thickspace x \leq 0 \\
				}
			\end{math}

			Vantaggi: gli stessi di ReLU, gli output della funzione 
			sono \em{quasi} centrati in 0, restiste meglio al rumore.

			Svantaggi: la funzione esponenziale è esosa da calcolare.
		\end{item}
	\end{itemize}

	\bigskip

	Non esiste una funzione di attivazione ottimale per qualsiasi
	rete neurale. In genere, la sigmoide e la tangente iperbolica
	sono subottimali, mentre ReLU è la scelta più sicura. Le funzioni
	restanti sono essenzialmente situazionali.

\end{sile}
