\begin{sile}

	\strong{Deep Learning} é una ampia famiglia di tecniche per il
	machine learning dove le ipotesi prendono la forma di complessi
	circuiti algebrici fra loro interconnessi. Il termine "deep" si
	riferisce al fatto che i circuiti sono in genere organizzati in
	strati detti \strong{layer}, il che significa che i percorsi
	computazionali dagli input agli output sono costituiti da diversi
	step.

	Il deep learning ha origini nella modellazione matematica dei
	neuroni del cervello umano sotto forma di circuiti elettrici.
	Per questo motivo, le reti allenate mediante metodi di deep
	learning sono spesso anche chiamate \strong{reti neurali}
	(\strong{neural network}).

	L'esempio di rete neurale piú semplice (e storicamente piú
	datata) é il \strong{percettrone}, matematicamente composto
	da:

	\begin{itemize}
		\begin{item}
			Un vettore \math{k}-dimensionale \math{\bi{x}} di
			attributi;
		\end{item}
		\begin{item}
			Una funzione \math{f(\bi{x})}, che restituisce un
			vettore \math{k}-dimensionale. Ciascuna componente
			\math{f_{i}(\bi{x})} di tale vettore é un numero
			intero (positivo o negativo) che rappresenta il
			valore di \math{\bi{x}} rispetto all'\math{i}-esimo
			attributo;
		\end{item}
		\begin{item}
			Un vettore \math{k}-dimensionale \math{\bi{w}}, dove
			ciascuna componente \math{w_{i}} é un numero
			intero (strettamente positivo) che rappresenta il
			peso da assegnare all'\math{i}-esimo attributo;
		\end{item}
		\begin{item}
			Una \strong{funzione di attivazione}, definita come il
			prodotto scalare fra il vettore dei pesi \math{\bi{w}}
			ed il vettore \math{f(\bi{x})}:

			\begin[mode = display]{math}
				\mi{activation}_{\bi{w}} (\bi{x}) =
				\sum_{i} w_{i} f_{i} (\bi{x}) =
				\bi{w} \cdot f(\bi{x})
			\end{math}
		\end{item}
		\begin{item}
			La funzione di output, che puo restituire esclusivamente
			+1 oppure -1, definita come il segno della funzione di
			attivazione:

			\begin[mode = display]{math}
				\mi{output}_{\bi{w}} (\bi{x}) =
				\mi{sgn} (\mi{activation}_{\bi{w}} (\bi{x})) =
				\frac{\abs{\mi{activation}_{\bi{w}} (\bi{x})}}{
				\mi{activation}_{\bi{w}} (\bi{x})}
			\end{math}
		\end{item}
	\end{itemize}

	\bigskip

	Il percettrone puo essere utilizzato per risolvere un
	problema di classificazione binaria, similmente a come
	sono stati impiegati gli alberi di decisione. In tal
	senso, il vettore \math{\bi{w}} rappresenta quanto e
	rilevante ai fini dell'appartenenza alla classe ciascun
	attributo, mentre la funzione di output rappresenta il
	risultato della classificazione: se il suo risultato e
	+1, allora \math{\bi{x}} appartiene alla classe (e un
	esempio positivo), mentre se e -1 allora \math{\bi{x}}
	non appartiene alla classe (e un esempio negativo).

	In tal senso, la funzione di attivazione cosi calcolata
	ha anche una interpretazione geometrica. Essendo definita
	a partire dal prodotto scalare fra il vettore \math{f(\bi{x})}
	ed il vettore \math{\bi{w}}, il suo valore sara un numero
	positivo quando l'angolo compreso fra i due vettori e un
	angolo acuto, mentre sara un numero negativo quando l'angolo
	compreso fra i due vettori e un angolo ottuso. Infatti, il
	vettore \math{\bi{w}} divide il piano in due semipiani a
	partire dalla iper-retta a questo ortogonale: tutti i vettori
	che formano un angolo acuto con \math{\bi{w}} si troverrano
	nello stesso di \math{\bi{w}}, mentre quelli che formano un
	angolo ottuso si troveranno nel semipiano opposto. Per questo
	motivo, si dice che il percettrone é un \strong{classificatore
	lineare}, ovvero che classifica gli input sulla base di una
	combinazione lineare.

	Sia la funzione \math{f(x)} che l'input \math{x} stesso
	possono essere considerate note, ma lo stesso non si puó
	dire di \math{w}. E possibile costruire un percettrone in
	grado di apprendere \math{w} a partire dai dati che gli
	vengono forniti: per fare questo, si assuma di avere a 
	disposizione \math{n} input \math{\bi{x}_{1}, \bi{x}_{2},
	\unicodeellipsis, \bi{x}_{n}} per i quali giá é nota la
	loro classificazione, sia questa rispettivamente \math{y_{1},
	y_{2}, \unicodeellipsis, y_{n}}. Questo insieme, che fara da
	training set per il percettrone, puó essere costruito utilizzando
	una qualsiasi tecnica di training (holdout set, k-fold cross
	validation, ecc\ddd).

	Inizialmente, il vettore \math{\bi{w}} \math{k}-dimensionale
	viene impostato nullo (tutte le sue componenti hanno valore 0).
	Dopodiche, per ciascun \math{i}-esimo input \math{\bi{x}_{i}}
	viene operata la classificazione: se la classificazione e
	corretta, ovvero se \math{\mi{out}(\bi{x}_{i})} coincide
	con \math{y_{i}}, allora non viene fatto nulla. Se invece la
	classificazione non e corretta, ovvero se \math{\mi{out}
	(\bi{x}_{i})} e \math{y_{i}} non coincidono, \math{\bi{w}}
	viene aggiornato in modo che, se la classificazione venisse
	ripetuta sul medesimo input, sarebbe corretta.

	Nello specifico, \math{\bi{w}} viene sostituito con
	\math{\bi{w} + y_{i} f(\bi{x})}. Il motivo per cui
	questa sostituzione effettivamente corregge la classificazione
	va cercata nell'interpretazione geometrica della funzione di
	attivazione. Infatti, tenendo fisso \math{\bi{w}}, tale somma
	ruota il vettore nel semipiano opposto rispetto alla sua
	perpendicolare. In questo modo, il prodotto scalare fra il
	nuovo \math{\bi{w}} e \math{f(\bi{x})} avra certamente segno
	opposto rispetto al prodotto scalare fra \math{f(\bi{x})} ed
	il vecchio \math{\bi{w}}.

	Si noti peró come un vettore \math{\bi{w}} cosí costruito
	sará sempre un vettore passante per l'origine, e questo
	limita di molto le capacitá del percettrone. Per fare in
	modo che \math{\bi{w}} possa discostarsi dall'origine viene
	introdotto un ulteriore attributo, "fittizio", chiamato
	\strong{bias}, che ha valore 1 per ogni istanza del dataset,
	che equivale ad introdurre una dimensione aggiuntiva a tutti
	i suoi elementi.

	Ci si chiede se il percettrone possa sempre, dato un dataset su
	cui apprendere, classificare correttamente tutti i suoi elementi.
	Questo accade se e possibile separare i vettori del dataset in
	due semipiani, dove tutti i vettori che rappresentano gli esempi
	positivi si trovano nell'uno e tutti i vettori che rappresentano
	gli esempi negativi si trovano nell'altro. Un dataset per cui
	questo e possibile é detto \strong{linearmente separabile};
	sfortunatamente, non tutti i dataset rientrano in questa
	categoria.

	\begin{theorem}
		\strong{Teorema di convergenza del percettrone}. Se
		un dataset \math{D} é linearmente separabile, allora
		é garantito che un percettrone, compiendo un numero
		finito di errori, sia in grado di classificarlo
		interamente. 
	\end{theorem}

	Il percettrone presentato finora risolve il problema di
	classificazione binaria. É pero possibile estendere il
	modello di percettrone cosi presentato per permettergli
	di classificare un dataset in piú classi, fintanto che il
	loro numero é noto a priori: un percettrone con queste
	caratteristiche prende il nome di \strong{percettrone
	multiclasse}.

	Si assuma pertanto di avere un dataset i cui elementi sono da
	suddividere in \math{m} classi, enumerate a partire da 1. Un
	percettrone di questo tipo non ha un solo vettore \math{\bi{w}},
	ma bensí \math{m} vettori \math{\bi{w}_{1}, \bi{w}_{2},
	\unicodeellipsis, \bi{w}_{m}}, uno per ciascuna classe.

	La funzione di attivazione della classe \math{i}-esima e
	data dal prodotto scalare fra \math{f(\bi{x})} (che e comunque
	univoca) e l'\math{i}-esimo vettore dei pesi \math{\bi{w}_{i}}.
	La funzione di output del percettrone viene modificata come:

	\begin[mode = display]{math}
		\mi{output}(\bi{x}) = \mi{argmax}_{i} \bi{w}_{i} f(\bi{x})
	\end{math}

	Ovvero, viene restituita l'\math{i}-esima classe che massimizza
	il prodotto scalare fra il vettore dei pesi di tale classe e
	\math{f(\bi{x})}.

	Per addestrare il percettrone multiclasse si procede allo
	stesso modo, con la differenza che ad ogni passo occorre
	correggere i valori di due vettori di pesi anziche uno.
	Si assuma pertanto di avere a disposizione \math{n} input
	\math{\bi{x}_{1}, \bi{x}_{2}, \unicodeellipsis, \bi{x}_{n}}
	per i quali giá é nota la loro classificazione, sia questa
	rispettivamente \math{y_{1}, y_{2}, \unicodeellipsis, y_{n}}.

	A partire da \math{m} vettori \math{w_{1}, \unicodeellipsis,
	w_{m}} tutti inizialmente nulli, si cerca di classificare
	ciascun input \math{x_{i}} sulla base di tali vettori. Sia
	\math{y_{i}'} il risultato del percettrone per \math{\bi{x}_{i}}:
	se tale risultato coincide con l'effettiva classificazione, ovvero
	se \math{y_{i}' = y_{i}}, non viene fatto nulla. Se invece i due
	risultati non concordano, il vettore dei pesi \math{w_{i}'},
	relativo alla classe \math{i'} (quella errata) viene sostituito
	con \math{\bi{w}_{i}' - f(\bi{x})}, mentre il vettore dei pesi
	\math{w_{i}}, relativo alla classe \math{i} (quella corretta)
	viene sostituito con \math{\bi{w}_{i} + f(\bi{x})}.

	Si noti come, dato un dataset linearmente separabile, possa
	esistere piú di una iper-retta in grado di partizionarlo.
	Fra queste, quella da considerarsi migliore é quella che
	ha la massima distanza dagli elementi del dataset piú \em{esterni},
	ovvero quelli che si trovano piú vicino alla partizione opposta.
	L'algoritmo sopra riportato non garantisce di trovare la 
	iper-retta migliore, restituendone invece una qualsiasi
	(per quanto comunque corretta). Inoltre, il percettrone "puro"
	é prono all'overfitting, perché non é mai ammessa la possibilitá
	di un margine di errore.

	Una versione alternativa dell'algoritmo di costruzione del 
	percettrone prende il nome di \strong{MIRA} (\strong{Margin
	Infused Relaxed Algorithm}). L'algoritmo é un raffinamento
	del precedente, dove il passo di aggiornamento viene fatto
	introducendo un fattore di correzione \math{\tau}.

\end{sile}
