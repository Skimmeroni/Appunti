\begin{sile}

	\strong{Deep Learning} é una ampia famiglia di tecniche per il
	machine learning dove le ipotesi prendono la forma di complessi
	circuiti algebrici fra loro interconnessi. Il termine "deep" si
	riferisce al fatto che i circuiti sono in genere organizzati in
	strati detti \strong{layer}, il che significa che i percorsi
	computazionali dagli input agli output sono costituiti da diversi
	step.

	Il deep learning ha origini nella modellazione matematica dei
	neuroni del cervello umano sotto forma di circuiti elettrici.
	Per questo motivo, le reti allenate mediante metodi di deep
	learning sono spesso anche chiamate \strong{reti neurali}
	(\strong{neural network}).

	L'esempio di rete neurale piú semplice (e storicamente piú
	datata) é il \strong{percettrone}, matematicamente composto
	da:

	\begin{itemize}
		\begin{item}
			Un vettore \math{k}-dimensionale \math{\bi{x}} di
			attributi;
		\end{item}
		\begin{item}
			Una funzione \math{f(\bi{x})}, che restituisce un
			vettore \math{k}-dimensionale. Ciascuna componente
			\math{f_{i}(\bi{x})} di tale vettore é un numero
			intero (positivo o negativo) che rappresenta il
			valore di \math{\bi{x}} rispetto all'\math{i}-esimo
			attributo;
		\end{item}
		\begin{item}
			Un vettore \math{k}-dimensionale \math{\bi{w}}, dove
			ciascuna componente \math{w_{i}} é un numero
			intero (strettamente positivo) che rappresenta il
			peso da assegnare all'\math{i}-esimo attributo;
		\end{item}
		\begin{item}
			Una \strong{funzione di attivazione}, definita come il
			prodotto scalare fra il vettore dei pesi \math{\bi{w}}
			ed il vettore \math{f(\bi{x})}:

			\begin[mode = display]{math}
				\mi{activation}_{\bi{w}} {(\bi{x})} =
				\sum_{i} w_{i} f_{i} {(\bi{x})} =
				\bi{w} \cdot f{(\bi{x})}
			\end{math}
		\end{item}
		\begin{item}
			La funzione di output, che puo restituire esclusivamente
			+1 oppure -1, definita come il segno della funzione di
			attivazione:

			\begin[mode = display]{math}
				\mi{output}_{\bi{w}} {(\bi{x})} =
				\mi{sgn} {(\mi{activation}_{\bi{w}} {(\bi{x})})} =
				\frac{\abs{\mi{activation}_{\bi{w}} {(\bi{x})}}}{
				\mi{activation}_{\bi{w}} {(\bi{x})}}
			\end{math}
		\end{item}
	\end{itemize}

	\bigskip

	Il percettrone puo essere utilizzato per risolvere un
	problema di classificazione binaria, similmente a come
	sono stati impiegati gli alberi di decisione. In tal
	senso, il vettore \math{\bi{w}} rappresenta quanto e
	rilevante ai fini dell'appartenenza alla classe ciascun
	attributo, mentre la funzione di output rappresenta il
	risultato della classificazione: se il suo risultato e
	+1, allora \math{\bi{x}} appartiene alla classe (e un
	esempio positivo), mentre se e -1 allora \math{\bi{x}}
	non appartiene alla classe (e un esempio negativo).

	In tal senso, la funzione di attivazione cosi calcolata
	ha anche una interpretazione geometrica. Essendo definita
	a partire dal prodotto scalare fra il vettore \math{f(\bi{x})}
	ed il vettore \math{\bi{w}}, il suo valore sara un numero
	positivo quando l'angolo compreso fra i due vettori e un
	angolo acuto, mentre sara un numero negativo quando l'angolo
	compreso fra i due vettori e un angolo ottuso. Infatti, il
	vettore \math{\bi{w}} divide il piano in due semipiani a
	partire dalla iper-retta a questo ortogonale: tutti i vettori
	che formano un angolo acuto con \math{\bi{w}} si troverrano
	nello stesso di \math{\bi{w}}, mentre quelli che formano un
	angolo ottuso si troveranno nel semipiano opposto. Per questo
	motivo, si dice che il percettrone é un \strong{classificatore
	lineare}, ovvero che classifica gli input sulla base di una
	combinazione lineare.

	Sia la funzione \math{f(x)} che l'input \math{x} stesso
	possono essere considerate note, ma lo stesso non si puó
	dire di \math{w}. E possibile costruire un percettrone in
	grado di apprendere \math{w} a partire dai dati che gli
	vengono forniti: per fare questo, si assuma di avere a 
	disposizione \math{n} input \math{\bi{x}_{1}, \bi{x}_{2},
	\unicodeellipsis, \bi{x}_{n}} per i quali giá é nota la
	loro classificazione, sia questa rispettivamente \math{y_{1},
	y_{2}, \unicodeellipsis, y_{n}}. Questo insieme, che fara
	da training set per il percettrone, puó essere costruito
	utilizzando una qualsiasi tecnica di training (holdout set,
	k-fold cross validation, ecc\ddd).

	Inizialmente, il vettore \math{\bi{w}} \math{k}-dimensionale
	viene impostato nullo (tutte le sue componenti hanno valore 0).
	Dopodiche, per ciascun \math{i}-esimo input \math{\bi{x}_{i}}
	viene operata la classificazione: se la classificazione e
	corretta, ovvero se \math{\mi{out}(\bi{x}_{i})} coincide
	con \math{y_{i}}, allora non viene fatto nulla. Se invece la
	classificazione non e corretta, ovvero se \math{\mi{out}
	(\bi{x}_{i})} e \math{y_{i}} non coincidono, \math{\bi{w}}
	viene aggiornato in modo che, se la classificazione venisse
	ripetuta sul medesimo input, sarebbe corretta.

	Nello specifico, \math{\bi{w}} viene sostituito con
	\math{\bi{w} + y_{i} f(\bi{x})}. Il motivo per cui
	questa sostituzione effettivamente corregge la classificazione
	va cercata nell'interpretazione geometrica della funzione di
	attivazione. Infatti, tenendo fisso \math{\bi{w}}, tale somma
	ruota il vettore nel semipiano opposto rispetto alla sua
	perpendicolare. In questo modo, il prodotto scalare fra il
	nuovo \math{\bi{w}} e \math{f(\bi{x})} avra certamente segno
	opposto rispetto al prodotto scalare fra \math{f(\bi{x})} ed
	il vecchio \math{\bi{w}}.

	Si noti peró come un vettore \math{\bi{w}} cosí costruito
	sará sempre un vettore passante per l'origine, e questo
	limita di molto le capacitá del percettrone. Per fare in
	modo che \math{\bi{w}} possa discostarsi dall'origine viene
	introdotto un ulteriore attributo, "fittizio", chiamato
	\strong{bias}, che ha valore 1 per ogni istanza del dataset,
	che equivale ad introdurre una dimensione aggiuntiva a tutti
	i suoi elementi.

	Ci si chiede se il percettrone possa sempre, dato un dataset su
	cui apprendere, classificare correttamente tutti i suoi elementi.
	Questo accade se e possibile separare i vettori del dataset in
	due semipiani, dove tutti i vettori che rappresentano gli esempi
	positivi si trovano nell'uno e tutti i vettori che rappresentano
	gli esempi negativi si trovano nell'altro. Un dataset per cui
	questo e possibile é detto \strong{linearmente separabile};
	sfortunatamente, non tutti i dataset rientrano in questa
	categoria.

	\begin{theorem}
		\strong{Teorema di convergenza del percettrone}. Se
		un dataset \math{D} é linearmente separabile, allora
		é garantito che un percettrone, compiendo un numero
		finito di errori, sia in grado di classificarlo
		interamente. 
	\end{theorem}

	Il percettrone presentato finora risolve il problema di
	classificazione binaria. É pero possibile estendere il
	modello di percettrone cosi presentato per permettergli
	di classificare un dataset in piú classi, fintanto che il
	loro numero é noto a priori: un percettrone con queste
	caratteristiche prende il nome di \strong{percettrone
	multiclasse}.

	Si assuma pertanto di avere un dataset i cui elementi sono da
	suddividere in \math{m} classi, enumerate a partire da 1. Un
	percettrone di questo tipo non ha un solo vettore \math{\bi{w}},
	ma bensí \math{m} vettori \math{\bi{w}_{1}, \bi{w}_{2},
	\unicodeellipsis, \bi{w}_{m}}, uno per ciascuna classe.

	La funzione di attivazione della classe \math{i}-esima e
	data dal prodotto scalare fra \math{f(\bi{x})} (che e comunque
	univoca) e l'\math{i}-esimo vettore dei pesi \math{\bi{w}_{i}}.
	La funzione di output del percettrone viene modificata come:

	\begin[mode = display]{math}
		\mi{output}(\bi{x}) = \mi{argmax}_{i} \bi{w}_{i} f(\bi{x})
	\end{math}

	Ovvero, viene restituita l'\math{i}-esima classe che massimizza
	il prodotto scalare fra il vettore dei pesi di tale classe e
	\math{f(\bi{x})}.

	Per addestrare il percettrone multiclasse si procede allo
	stesso modo, con la differenza che ad ogni passo occorre
	correggere i valori di due vettori di pesi anziche uno.
	Si assuma pertanto di avere a disposizione \math{n} input
	\math{\bi{x}_{1}, \bi{x}_{2}, \unicodeellipsis, \bi{x}_{n}}
	per i quali giá é nota la loro classificazione, sia questa
	rispettivamente \math{y_{1}, y_{2}, \unicodeellipsis, y_{n}}.

	A partire da \math{m} vettori \math{w_{1}, \unicodeellipsis,
	w_{m}} tutti inizialmente nulli, si cerca di classificare
	ciascun input \math{x_{i}} sulla base di tali vettori. Sia
	\math{y_{i}'} il risultato del percettrone per \math{\bi{x}_{i}}:
	se tale risultato coincide con l'effettiva classificazione, ovvero
	se \math{y_{i}' = y_{i}}, non viene fatto nulla. Se invece i due
	risultati non concordano, il vettore dei pesi \math{w_{i}'},
	relativo alla classe \math{i'} (quella errata) viene sostituito
	con \math{\bi{w}_{i}' - f(\bi{x})}, mentre il vettore dei pesi
	\math{w_{i}}, relativo alla classe \math{i} (quella corretta)
	viene sostituito con \math{\bi{w}_{i} + f(\bi{x})}.

	Si noti come, dato un dataset linearmente separabile,
	possa esistere piú di una iper-retta in grado di
	partizionarlo. Fra queste, quella da considerarsi
	migliore é quella che ha la massima distanza dagli
	elementi del dataset piú \em{esterni}, ovvero quelli
	che si trovano piú vicino alla partizione opposta.
	L'algoritmo sopra riportato non garantisce di trovare
	la iper-retta migliore, restituendone invece una qualsiasi
	(per quanto comunque corretta). Inoltre, il percettrone
	"puro" é prono all'overfitting, perché non é mai ammessa
	la possibilitá di un margine di errore.

	Una versione alternativa dell'algoritmo di costruzione del 
	percettrone prende il nome di \strong{MIRA} (\strong{Margin
	Infused Relaxed Algorithm}). L'algoritmo é un raffinamento
	del precedente, dove il passo di aggiornamento viene fatto
	introducendo un fattore di correzione \math{\tau}.

	Un percettrone con queste caratteristiche separa il dataset
	che gli viene fornito (ammesso che sia possibile farlo) in
	maniera netta e completamente disambigua. Tuttavia, in genere
	un dataset presenta da un lato del rumore e dall'altro lato
	degli elementi la cui classificazione é incerta. Un modello
	migliore di percettrone, il \strong{percettrone probabilistico},
	non solo assegna ciascun elemento del dataset ad una classe
	(apprendendo da questo), ma restituisce anche una probabilitá
	che la classificazione in questione sia corretta.

	L'iper-retta costruita da un percettrone probabilistico
	rappresenta comunque la separazione del dataset in due
	classi, ma oltre a questo la vicinanza di ciascun elemento
	all'iper-retta in questione rappresenta il grado di certezza
	della classificazione dello stesso. In altre parole, piú un
	elemento si trova vicino alla retta e piú la classificazione
	che gli é stata data é incerta, mentre piú distante si trova
	dalla retta e piú la classificazione che gli é stata data é
	certa; se un elemento si trova precisamente lungo la retta,
	allora vi é la massima incertezza in merito a quale classe
	assegnarlo.

	Naturalmente, la distanza di un punto dalla retta é data dal
	segmento che li congiunge e cade sulla perpendicolare alla
	retta stessa, ovvero al vettore gradiente. La probabilitá
	associata alla classificazione di un punto non é altro che
	una trasformazione non lineare associata a tale distanza, che
	converte gradienti in probabilitá. Tale trasformazione fará da
	funzione di attivazione per il percettrone, che peró anziché
	restituire +1 oppure -1 restituisce una probabilitá, ovvero un
	numero reale compreso fra 0 e 1.

	Quale debba essere questa funzione é un ambito di ricerca a sé
	stante. Una delle piú famose é la \strong{funzione sigmoidea},
	anche detta semplicemente \strong{sigmoide}:

	\begin[mode = display]{math}
		\mi{sig} {(x)} = \frac{1}{1 + e^{-x}} = \frac{e^{x}}{1 + e^{x}}
	\end{math}

	Questa funzione ha per codominio \math{[0, 1]}, pertanto é
	effettivamente una funzione di probabilitá. Inoltre, dal
	punto di vista strettamente computazionale, ha una proprietá
	molto interessante: é possibile esprimere la sua derivata in
	funzione di sé stessa:

	\begin[mode = display]{math}
		\frac{d}{dx} {(\mi{sig} {(x)})} =
		\frac{(1 + e^{x})\frac{d}{dx}(e^{x}) -
		e^{x}\frac{d}{dx}(1 + e^{x})}{(1 + e^{x})^{2}} =
		\frac{(1 + e^{x}) e^{x} - e^{x} e^{x}}{(1 + e^{x})^{2}} =
		\frac{e^{x}}{(1 + e^{x})^{2}} =
		{(\frac{1}{1 + e^{x}})} {(\frac{e^{x}}{1 + e^{x}})} =
		{(\frac{1 + e^{x} - e^{x}}{1 + e^{x}})} \mi{sig} {(x)} =
		{(1 - \mi{sig} {(x)})} \mi{sig} {(x)}
	\end{math}

	Nel contesto del percettrone probabilistico, sia \math{\bi{w}}
	il vettore dei pesi. Una variante della funzione sigmoidea é la
	funzione \strong{softmax}:

	\begin[mode = display]{math}
		\mi{softmax} {(x)} =
		\frac{e^{\bi{wx}}}{e^{\bi{wx}} + e^{(\bi{1} - \bi{w})\bi{x}}}
	\end{math}

	Aumentando il valore di \math{\bi{w}} aumenta anche la \em{stifness}
	della curva. In particolare, con \math{\bi{w}} tendente all'infinito,
	la funzione diventa indistinguibile dalla funzione max.

	Prende il nome di \strong{likelihood} la probabilitá, dato un modello
	avente parametri \math{\theta}, di osservare un certo insieme di dati
	sulla base di una certa assegnazione di \math{\theta}:

	\begin[mode = display]{math}
		\theta_{ML} = \mi{argmax}_{\theta} P(\bi{X} | \theta)
	\end{math}

	Una volta stabilito il problema, si assume che i dati di tale
	problema siano stocasticamente indipendenti fra loro, ovvero
	che le singole osservazioni non sono influenzate dalle osservazioni
	precedenti. Diviene allora possibile scrivere:

	\begin[mode = display]{math}
		\theta_{ML} =
		\mi{argmax}_{\theta} P(\bi{X} | \theta) =
		\mi{argmax}_{\theta} \Pi_{i} P_{\theta} (X_{i})
	\end{math}

	Si noti peró come gli elementi del dataset da fornire al
	percettrone non abbiano solamente gli attributi \math{\bi{X}}
	ma anche una classificazione (da apprendere). Per questo motivo,
	si preferisce esprimere la likelihood in questa forma:

	\begin[mode = display]{math}
		\theta* =
		\mi{argmax}_{\theta} P(\bi{Y} | \bi{X}, \theta) =
		\mi{argmax}_{\theta} \Pi_{i} P_{\theta} (y_{i} | x_{i})
	\end{math}

	Rispetto al modello di percettrone probabilistico, i parametri
	\math{\theta} corrispondono ai suoi pesi. Sostituendo poi con,
	ad esempio, la funzione softmax, si ha:

	\begin[mode = display]{math}
		l{(w)} = \Pi_{i} \frac{e^{{w_{y}}_{i} \cdot x_{i}}}{\sum_{y} e^{w_{y} \cdot x_{i}}}
	\end{math}

	Per comoditá si preferisce lavorare non sulla likelihood, ma bensí
	sulla \strong{log likelihood}, ovvero sul suo logaritmo naturale:

	\begin[mode = display]{math}
		ll{(w)} = \mi{log} {(l{(w)})} = \sum_{i} \mi{log} P_{w} {(y_{i} | x_{i})} =
		\sum_{i} {w_{y}}_{i} \cdot x_{i} - \mi{log} \sum_{y} e^{w_{y} \cdot x_{i}}
	\end{math}

	Massimizzare tale funzione significa, di fatto, selezionare i
	parametri \math{\bi{w}} che migliorano il trade-off tra le assegnazioni
	di probabilitá a tutti gli elementi del dataset. Aumentando i pesi, gli
	elementi classificati erroneamente avranno dei valori di probabilitá
	bassi, e la (log) likelihood scenderá. Per questo motivo, una maggior
	presenza di rumore richiede che i pesi siano piccoli, in modo tale da
	avere una transizione fra le classificazioni che sia sufficientemente
	uniforme.

	\begin[mode = display]{math}
		\mi{max}_{w} ll{(w)} =
		\mi{max}_{w} \sum_{i} \mi{log} P {(y_{i} | x_{i}, w)} =
		\mi{max}_{w} \sum_{i} \mi{log} \frac{e^{{w_{y}}_{i} \cdot
		f(x_{i})}}{\sum_{y} e^{w_{y} \cdot f(x_{i})}}
	\end{math}

	Spesso, anziché massimizzare la log likelihood, si
	preferisce minimizzare il suo opposto, detto \strong{loss
	function} (\strong{funzione di loss}).

	\begin[mode = display]{math}
		\mi{max}_{w} ll{(w)} = \mi{min}_{w} -ll{(w)}
	\end{math}

	Calcolare questa massimizzazione/minimizzazione significa, di fatto,
	calcolare i punti della funzione in cui il gradiente si annulla. Se
	la funzione ha un numero di dimensioni contenuto ed ha un gradiente
	facilmente calcolabile, come ad esempio nel caso del sigmoide, é
	possibile farlo analiticamente. Se la funzione é multidimensionale,
	questo approccio diviene insostenibile, ed é preferibile calcolare
	i punti di ottimo in maniera approssimata.

	Un algoritmo che permette di farlo prende il nome di \strong{steepest
	descent}, e si basa sull'osservazione che, per raggiungere un punto
	di ottimo a partire da un punto qualsiasi, la direzione che permette
	di raggiungerlo il piú velocemente possibile é quella del gradiente
	valutato nel punto stesso.

	Si consideri, per comoditá, il caso bidimensionale. Indicando con
	\math{\Delta} uno spostamento infinitesimo e con \math{\epsilon}
	una soglia minima, L'intenzione é quella di minimizzare la funzione
	\math{g}:

	\begin[mode = display]{math}
		\mi{min}_{\Delta: \Delta_{1} + \Delta_{2} \leq \epsilon} g(w + \Delta)
	\end{math}

	L'espansione di Taylor al primo ordine di tale funzione é approssimabile a:

	\begin[mode = display]{math}
		g{(w + \Delta)} \approx
		\frac{\partial g}{\partial w_{1}} \Delta_{1} +
		\frac{\partial g}{\partial w_{2}} \Delta_{2}
	\end{math}

	Questo é, di fatto, un prodotto scalare fra due vettori. Ricordando come
	il prodotto scalare abbia valore minimo quando i due vettori hanno verso
	contrario, si ha:

	\begin[mode = display]{math}
		\mi{min}_{\Delta: \Delta_{1} + \Delta_{2} \leq \epsilon} g{(w + \Delta)} \approx
		\mi{min}_{\Delta: \Delta_{1} + \Delta_{2} \leq \epsilon}
		\frac{\partial g}{\partial w_{1}} \Delta_{1} +
		\frac{\partial g}{\partial w_{2}} \Delta_{2} =
		- \nabla {(g)} \frac{\epsilon}{\abs{\abs{\nabla (g)}}} =
		- {[\frac{\partial g}{\partial w_{1}}, \frac{\partial g}{\partial w_{2}}]}^{T}
		\frac{\epsilon}{\abs{\abs{{[\frac{\partial g}{\partial w_{1}},
		\frac{\partial g}{\partial w_{2}}]}^{T}}}}
	\end{math}

	L'idea é quindi quella di partire da un valore qualsiasi per \math{w}
	(anche il vettore nullo) e poi effettuare ripetutamente degli aggiornamenti:

	\begin[mode = display]{math}
		w \leftarrow w - \alpha \nabla {(g{(w)})} = w - \alpha \nabla {(ll{(w)})} =
		w - \alpha \nabla {(\sum_{i = 1}^{m} \mi{log} P{(y_{i} | x_{i}, w)})}
	\end{math}

	Dove \math{\alpha} é un fattore di correzione chiamato \strong{learning rate}.

\end{sile}
